{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef220af2-bd3b-4a99-80e9-39a5a427db06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /home/ec2-user/SageMaker/gs-ds-env/lightgbm311/sm_docker\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import json\n",
    "import tarfile\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "\n",
    "PROJECT_ROOT = Path().resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742eae1f-8382-46a2-aa0d-c1533294ba85",
   "metadata": {},
   "source": [
    "## Í≤ΩÎ°ú ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131613b1-c6bd-4ded-a6ec-48560bf18f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = \"retail-mlops-edu-2026\"\n",
    "S3_DATA_PREFIX = \"edu-2w/hjsong/input\"\n",
    "S3_MODEL_PREFIX = \"edu-2w/hjsong/model\"\n",
    "S3_TRAIN_PREFIX = \"edu-2w/hjsong/data/train\"\n",
    "S3_VAL_PREFIX = \"edu-2w/hjsong/data/val\"\n",
    "\n",
    "sm_dir = {\n",
    "    \"train_path\": os.environ.get(\n",
    "        'SM_CHANNEL_TRAIN', PROJECT_ROOT / \"data/train\"\n",
    "    ),\n",
    "    \"val_path\": os.environ.get(\n",
    "        'SM_CHANNEL_VAL', PROJECT_ROOT / \"data/val\"\n",
    "    ),\n",
    "    \"model_path\": os.environ.get(\n",
    "        'SM_MODEL_DIR', PROJECT_ROOT / \"model\"\n",
    "    ),\n",
    "    \"output_path\": os.environ.get(\n",
    "        'SM_OUTPUT_DATA_DIR', PROJECT_ROOT / \"output\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d167109-dab0-4c35-a2aa-ead6ec4e75e5",
   "metadata": {},
   "source": [
    "## Î™®Îç∏Í¥ÄÎ†® ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec1ba959-6d77-4ca3-8523-794bea2c35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split={\n",
    "  \"val_ratio\": 0.2,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "model_name =\"titanic_model\"\n",
    "model_version=\"1.0.0\"\n",
    "model_description=\"Titanic Model\"\n",
    "model_algo=\"lightgbm\"\n",
    "hyperparameters={\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046955e-2882-47fd-a4fe-1cb41906f7a7",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ Ïã§Ìñâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2419f4-c030-4e43-9c3d-25677ba89c80",
   "metadata": {},
   "source": [
    "### Ï†ÑÏ≤òÎ¶¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3de607-ad50-4ae4-8fdf-40de0f565611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ  Loading data...\n",
      "üîç Data shape: (891, 12)\n",
      "üîç Columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "üöÄ  Preprocessing data...\n",
      "üîç Features shape: (891, 12)\n",
      "üîç Features: ['passenger_id', 'target', 'pclass', 'name', 'sex', 'age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "üíæ Saving preprocessed data...\n",
      "üíæ Saved: /home/ec2-user/SageMaker/gs-ds-env/lightgbm311/sm_docker/data/train/train.csv\n",
      "üíæ Saved S3: s3://retail-mlops-edu-2026/edu-2w/hjsong/data/train/train.csv\n",
      "üíæ Saved: /home/ec2-user/SageMaker/gs-ds-env/lightgbm311/sm_docker/data/val/validation.csv\n",
      "üíæ Saved S3: s3://retail-mlops-edu-2026/edu-2w/hjsong/data/val/validation.csv\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"üöÄ  Loading data...\")\n",
    "key = f\"{S3_DATA_PREFIX}/train.csv\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "obj = s3.get_object(Bucket=S3_BUCKET, Key=key)\n",
    "df = pd.read_csv(BytesIO(obj[\"Body\"].read()))\n",
    "print(f\"üîç Data shape: {df.shape}\")\n",
    "print(f\"üîç Columns: {list(df.columns)}\")\n",
    "\n",
    "print(\"üöÄ  Preprocessing data...\")\n",
    "df_preprocessed = df.copy()\n",
    "df_preprocessed = df_preprocessed.rename(columns={\n",
    "    'PassengerId': 'passenger_id',\n",
    "    'Survived': 'target',\n",
    "    'Pclass': 'pclass',\n",
    "    'Name': 'name',\n",
    "    'Sex': 'sex',\n",
    "    'Age': 'age',\n",
    "})\n",
    "\n",
    "\n",
    "# Í∏∞Î≥∏ Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ + ÌÉÄÏûÖ Í∏∞Ï§Ä Îã®Ïàú Ï†ÑÏ≤òÎ¶¨\n",
    "numeric_cols = df_preprocessed.select_dtypes(include=\"number\").columns\n",
    "object_cols = df_preprocessed.select_dtypes(exclude=\"number\").columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if df_preprocessed[col].isnull().any():\n",
    "        df_preprocessed[col] = df_preprocessed[col].fillna(0)\n",
    "    df_preprocessed[col] = pd.to_numeric(df_preprocessed[col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "for col in object_cols:\n",
    "    if df_preprocessed[col].isnull().any():\n",
    "        if df_preprocessed[col].dropna().empty:\n",
    "            df_preprocessed[col] = df_preprocessed[col].fillna(\"\")\n",
    "        else:\n",
    "            df_preprocessed[col] = df_preprocessed[col].fillna(df[col].mode()[0])\n",
    "    # Î≤îÏ£ºÌòï Ïª¨ÎüºÏùÄ Í∞ÑÎã®Ìûà Ïà´Ïûê Ïù∏ÏΩîÎî©\n",
    "    df_preprocessed[col] = df_preprocessed[col].astype(str)\n",
    "    df_preprocessed[col] = pd.factorize(df_preprocessed[col])[0]\n",
    "\n",
    "print(f\"üîç Features shape: {df_preprocessed.shape}\")\n",
    "print(f\"üîç Features: {list(df_preprocessed.columns)}\")\n",
    "\n",
    "if \"target\" not in df_preprocessed.columns:\n",
    "    raise ValueError(\"Column 'target' not found after preprocessing\")\n",
    "\n",
    "val_ratio = train_val_split[\"val_ratio\"]\n",
    "random_state = train_val_split[\"random_state\"]\n",
    "\n",
    "train_df_preprocessed, val_df_preprocessed = train_test_split(\n",
    "    df_preprocessed,\n",
    "    test_size=val_ratio,\n",
    "    random_state=random_state,\n",
    "    stratify=df_preprocessed[\"target\"],\n",
    ")\n",
    "\n",
    "print(\"üíæ Saving preprocessed data...\")\n",
    "def save_upload_to_s3(output_dir, filename, s3_prefix,df=None):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    if df is not None:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"üíæ Saved: {output_path}\")\n",
    "    \n",
    "    # S3 Ï†ÄÏû•\n",
    "    s3_key = f\"{s3_prefix}/{filename}\"\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    s3.upload_file(output_path, S3_BUCKET, s3_key)\n",
    "    print(f\"üíæ Saved S3: s3://{S3_BUCKET}/{s3_key}\")\n",
    "save_upload_to_s3(sm_dir['train_path'], \"train.csv\",S3_TRAIN_PREFIX, train_df_preprocessed)\n",
    "save_upload_to_s3(sm_dir['val_path'], \"validation.csv\",S3_VAL_PREFIX, val_df_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b8926-6f76-4d55-92a6-c0e275e6aa52",
   "metadata": {},
   "source": [
    "### ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e900812c-5376-4753-9c46-f1cae222ad5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Train step started.\n",
      "üéØ Training LightGBM tree model...\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "‚úÖ Model training completed!\n",
      "üöÄ save model/artifact in model path.\n",
      "‚úÖ Model saved: /home/ec2-user/SageMaker/gs-ds-env/lightgbm311/sm_docker/model/titanic_model.joblib.joblib\n",
      "‚úÖ Model artifact created: /home/ec2-user/SageMaker/gs-ds-env/lightgbm311/sm_docker/model/model.tar.gz\n",
      "‚úÖ Model artifact uploaded: s3://retail-mlops-edu-2026/edu-2w/hjsong/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÌïôÏäµ\n",
    "\n",
    "print(\"üöÄ Train step started.\")\n",
    "train_path = sm_dir['train_path']\n",
    "if os.path.isdir(train_path):\n",
    "    train_path = os.path.join(train_path, \"train.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "target_col = \"survived\" if \"survived\" in train_df.columns else \"target\"\n",
    "X_train = train_df.drop(target_col, axis=1)\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "print(\"üéØ Training LightGBM tree model...\")\n",
    "model = lgb.LGBMClassifier(**hyperparameters)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training completed!\")\n",
    "\n",
    "print(\"üöÄ save model/artifact in model path.\")\n",
    "model_dir = sm_dir['model_path']\n",
    "model_name=f\"{model_name}.joblib\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"‚úÖ Model saved: {model_path}\")\n",
    "\n",
    "artifact_path = os.path.join(model_dir, \"model.tar.gz\")\n",
    "with tarfile.open(artifact_path, \"w:gz\") as tar:\n",
    "    tar.add(model_dir, arcname=\".\")\n",
    "print(f\"‚úÖ Model artifact created: {artifact_path}\")\n",
    "\n",
    "\n",
    "key = S3_MODEL_PREFIX + \"/\" + os.path.basename(artifact_path)\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(artifact_path, S3_BUCKET, key)\n",
    "uploaded_uri = f\"s3://{S3_BUCKET}/{key}\"\n",
    "print(f\"‚úÖ Model artifact uploaded: {uploaded_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aad16b-0c5e-40be-ae94-0bff80d505ac",
   "metadata": {},
   "source": [
    "### ÌèâÍ∞Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3275d09a-07ab-4586-9b35-c9ac8805baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate step started.\n",
      "‚úÖ Validation Accuracy: 0.7765\n",
      "‚úÖ Metrics saved: /home/ec2-user/SageMaker/gs-ds-env/lightgbm311/sm_docker/output/evaluation.json\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÌèâÍ∞Ä\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Evaluate step started.\")\n",
    "\n",
    "\n",
    "val_path = sm_dir['val_path']\n",
    "model_path = sm_dir['model_path']\n",
    "output_path = sm_dir['output_path']\n",
    "\n",
    "if os.path.isdir(val_path):\n",
    "    val_path = os.path.join(val_path, \"validation.csv\")\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "target_col = \"survived\" if \"survived\" in val_df.columns else \"target\"\n",
    "X_val = val_df.drop(target_col, axis=1)\n",
    "y_val = val_df[target_col]\n",
    "\n",
    "if os.path.isdir(model_path):\n",
    "    model_path = os.path.join(model_path, model_name)\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "preds = model.predict(X_val)\n",
    "acc = accuracy_score(y_val, preds)\n",
    "metrics = {\"accuracy\": acc}\n",
    "print(f\"‚úÖ Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "\n",
    "metrics = {\n",
    "        \"model_path\": str(model_path),\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "metrics_path = os.path.join(output_path, \"evaluation.json\")\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(f\"‚úÖ Metrics saved: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77d1b5-2d94-46a2-9dd2-48c68e854bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_lightgbm311",
   "language": "python",
   "name": "conda_lightgbm311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
